{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1cf398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaush\\anaconda3\\envs\\tfenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kaush\\anaconda3\\envs\\tfenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=104, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MobileNetV3 model initiation\n",
    "\n",
    "import torch\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_classes = 104\n",
    "\n",
    "model = mobilenet_v3_small(pretrained=False)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('final_image_classifier.pth', map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed74cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1.jpg: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2.jpg: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Training dataset - Encoding\n",
    "\n",
    "import csv\n",
    "\n",
    "def normalize_label(label):\n",
    "    return label.strip().lower()\n",
    "\n",
    "class_name_to_id = {}\n",
    "with open(r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\category_id.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            idx, name = parts\n",
    "            class_name_to_id[normalize_label(name)] = int(idx)\n",
    "\n",
    "num_classes = max(class_name_to_id.values()) + 1\n",
    "\n",
    "train_labels_encoded = {}\n",
    "with open(r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\Kaush Stuff\\FoodSeg103_export\\train\\labels.csv\", newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        filename = row['filename']\n",
    "        labels = row['labels'].split(',')\n",
    "        label_indices = []\n",
    "        for label in labels:\n",
    "            norm_label = normalize_label(label)\n",
    "            if norm_label in class_name_to_id:\n",
    "                idx = class_name_to_id[norm_label]\n",
    "                if idx < num_classes:\n",
    "                    label_indices.append(idx)\n",
    "                else:\n",
    "                    print(f\"Warning: Index {idx} for class '{norm_label}' out of bounds for image {filename}\")\n",
    "            else:\n",
    "                print(f\"Warning: Class '{norm_label}' not found in mapping for image {filename}\")\n",
    "                print(\"Check for trailing spaces, capitalization, or typos!\")\n",
    "        label_vector = [0] * num_classes\n",
    "        for idx in label_indices:\n",
    "            label_vector[idx] = 1\n",
    "        train_labels_encoded[filename] = label_vector\n",
    "\n",
    "for k, v in list(train_labels_encoded.items())[:3]:\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d257ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "1.jpg: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2.jpg: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Validation dataset - Encoding\n",
    "\n",
    "import csv\n",
    "\n",
    "def normalize_label(label):\n",
    "    return label.strip().lower()\n",
    "\n",
    "class_name_to_id = {}\n",
    "with open(r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\category_id.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            idx, name = parts\n",
    "            class_name_to_id[normalize_label(name)] = int(idx)\n",
    "\n",
    "num_classes = max(class_name_to_id.values()) + 1\n",
    "\n",
    "val_labels_encoded = {}\n",
    "with open(r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\Kaush Stuff\\FoodSeg103_export\\validation\\labels.csv\", newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        filename = row['filename']\n",
    "        labels = row['labels'].split(',')\n",
    "        label_indices = []\n",
    "        for label in labels:\n",
    "            norm_label = normalize_label(label)\n",
    "            if norm_label in class_name_to_id:\n",
    "                idx = class_name_to_id[norm_label]\n",
    "                if idx < num_classes:\n",
    "                    label_indices.append(idx)\n",
    "                else:\n",
    "                    print(f\"Warning: Index {idx} for class '{norm_label}' out of bounds for image {filename}\")\n",
    "            else:\n",
    "                print(f\"Warning: Class '{norm_label}' not found in mapping for image {filename}\")\n",
    "                print(\"Check for trailing spaces, capitalization, or typos!\")\n",
    "        label_vector = [0] * num_classes\n",
    "        for idx in label_indices:\n",
    "            label_vector[idx] = 1\n",
    "        val_labels_encoded[filename] = label_vector\n",
    "\n",
    "for k, v in list(val_labels_encoded.items())[:3]:\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, labels, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.image_filenames = list(labels.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[img_name]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label, dtype=torch.float)  \n",
    "        return image, label\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_image_folder = r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\Kaush Stuff\\FoodSeg103_export\\train\"\n",
    "val_image_folder = r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\Kaush Stuff\\FoodSeg103_export\\validation\"\n",
    "\n",
    "train_dataset = CustomImageDataset(train_image_folder, train_labels_encoded, transform=train_transforms)\n",
    "val_dataset = CustomImageDataset(val_image_folder, val_labels_encoded, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation Function\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, multilabel_confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_class_names(txt_path):\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        class_names = [line.strip() for line in f if line.strip()]\n",
    "    return class_names\n",
    "\n",
    "def evaluate_model(model, class_txt_path):\n",
    "    class_names = load_class_names(class_txt_path)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Evaluating model\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            preds = (outputs > 0.5).float()\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    overall_acc = accuracy_score(all_labels.flatten(), all_preds.flatten())\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_acc:.4f}\")\n",
    "    print(f\"Weighted Precision: {precision:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "    print(\"Confusion Matrix (multilabel):\")\n",
    "    cm = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "    for idx, matrix in enumerate(cm):\n",
    "        print(f\"Class {class_names[idx]}:\")\n",
    "        print(matrix)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efdc33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:   0%|          | 0/67 [00:00<?, ?it/s]c:\\Users\\kaush\\anaconda3\\envs\\tfenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Evaluating model: 100%|██████████| 67/67 [00:29<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9738\n",
      "Weighted Precision: 0.7228\n",
      "Weighted Recall: 0.5483\n",
      "Weighted F1 Score: 0.6059\n",
      "\n",
      "Confusion Matrix (multilabel):\n",
      "Class 0\tbackground:\n",
      "[[   0    0]\n",
      " [   0 2135]]\n",
      "\n",
      "Class 1\tcandy:\n",
      "[[2123    1]\n",
      " [  10    1]]\n",
      "\n",
      "Class 2\tegg tart:\n",
      "[[2134    0]\n",
      " [   1    0]]\n",
      "\n",
      "Class 3\tfrench fries:\n",
      "[[2049    8]\n",
      " [  49   29]]\n",
      "\n",
      "Class 4\tchocolate:\n",
      "[[2115    2]\n",
      " [  17    1]]\n",
      "\n",
      "Class 5\tbiscuit:\n",
      "[[2038   20]\n",
      " [  57   20]]\n",
      "\n",
      "Class 6\tpopcorn:\n",
      "[[2130    1]\n",
      " [   3    1]]\n",
      "\n",
      "Class 7\tpudding:\n",
      "[[2133    1]\n",
      " [   1    0]]\n",
      "\n",
      "Class 8\tice cream:\n",
      "[[1793   65]\n",
      " [ 144  133]]\n",
      "\n",
      "Class 9\tcheese butter:\n",
      "[[1997   18]\n",
      " [ 110   10]]\n",
      "\n",
      "Class 10\tcake:\n",
      "[[1980   29]\n",
      " [  80   46]]\n",
      "\n",
      "Class 11\twine:\n",
      "[[2086    8]\n",
      " [  36    5]]\n",
      "\n",
      "Class 12\tmilkshake:\n",
      "[[2097   11]\n",
      " [  11   16]]\n",
      "\n",
      "Class 13\tcoffee:\n",
      "[[2071    7]\n",
      " [  32   25]]\n",
      "\n",
      "Class 14\tjuice:\n",
      "[[2073    8]\n",
      " [  39   15]]\n",
      "\n",
      "Class 15\tmilk:\n",
      "[[2103    4]\n",
      " [  19    9]]\n",
      "\n",
      "Class 16\ttea:\n",
      "[[2129    0]\n",
      " [   5    1]]\n",
      "\n",
      "Class 17\talmond:\n",
      "[[2104    7]\n",
      " [  21    3]]\n",
      "\n",
      "Class 18\tred beans:\n",
      "[[2121    0]\n",
      " [  13    1]]\n",
      "\n",
      "Class 19\tcashew:\n",
      "[[2125    0]\n",
      " [  10    0]]\n",
      "\n",
      "Class 20\tdried cranberries:\n",
      "[[2123    0]\n",
      " [  12    0]]\n",
      "\n",
      "Class 21\tsoy:\n",
      "[[2118    3]\n",
      " [  12    2]]\n",
      "\n",
      "Class 22\twalnut:\n",
      "[[2113    0]\n",
      " [  19    3]]\n",
      "\n",
      "Class 23\tpeanut:\n",
      "[[2133    0]\n",
      " [   2    0]]\n",
      "\n",
      "Class 24\tegg:\n",
      "[[2047   19]\n",
      " [  46   23]]\n",
      "\n",
      "Class 25\tapple:\n",
      "[[2077    6]\n",
      " [  41   11]]\n",
      "\n",
      "Class 26\tdate:\n",
      "[[2133    0]\n",
      " [   2    0]]\n",
      "\n",
      "Class 27\tapricot:\n",
      "[[2125    2]\n",
      " [   8    0]]\n",
      "\n",
      "Class 28\tavocado:\n",
      "[[2110    1]\n",
      " [  24    0]]\n",
      "\n",
      "Class 29\tbanana:\n",
      "[[2075    4]\n",
      " [  38   18]]\n",
      "\n",
      "Class 30\tstrawberry:\n",
      "[[1945   18]\n",
      " [  46  126]]\n",
      "\n",
      "Class 31\tcherry:\n",
      "[[2069   13]\n",
      " [  38   15]]\n",
      "\n",
      "Class 32\tblueberry:\n",
      "[[2070    7]\n",
      " [  12   46]]\n",
      "\n",
      "Class 33\traspberry:\n",
      "[[2111    2]\n",
      " [  13    9]]\n",
      "\n",
      "Class 34\tmango:\n",
      "[[2122    1]\n",
      " [  10    2]]\n",
      "\n",
      "Class 35\tolives:\n",
      "[[2120    0]\n",
      " [  14    1]]\n",
      "\n",
      "Class 36\tpeach:\n",
      "[[2109    8]\n",
      " [  10    8]]\n",
      "\n",
      "Class 37\tlemon:\n",
      "[[1931   32]\n",
      " [  80   92]]\n",
      "\n",
      "Class 38\tpear:\n",
      "[[2121    0]\n",
      " [  14    0]]\n",
      "\n",
      "Class 39\tfig:\n",
      "[[2130    0]\n",
      " [   5    0]]\n",
      "\n",
      "Class 40\tpineapple:\n",
      "[[2087   12]\n",
      " [  29    7]]\n",
      "\n",
      "Class 41\tgrape:\n",
      "[[2094    6]\n",
      " [  21   14]]\n",
      "\n",
      "Class 42\tkiwi:\n",
      "[[2118    4]\n",
      " [  10    3]]\n",
      "\n",
      "Class 43\tmelon:\n",
      "[[2130    1]\n",
      " [   4    0]]\n",
      "\n",
      "Class 44\torange:\n",
      "[[2052   13]\n",
      " [  52   18]]\n",
      "\n",
      "Class 45\twatermelon:\n",
      "[[2126    1]\n",
      " [   5    3]]\n",
      "\n",
      "Class 46\tsteak:\n",
      "[[1707   91]\n",
      " [ 174  163]]\n",
      "\n",
      "Class 47\tpork:\n",
      "[[1910   30]\n",
      " [ 181   14]]\n",
      "\n",
      "Class 48\tchicken duck:\n",
      "[[1631  110]\n",
      " [ 245  149]]\n",
      "\n",
      "Class 49\tsausage:\n",
      "[[2064   18]\n",
      " [  46    7]]\n",
      "\n",
      "Class 50\tfried meat:\n",
      "[[2046    5]\n",
      " [  83    1]]\n",
      "\n",
      "Class 51\tlamb:\n",
      "[[2105    2]\n",
      " [  25    3]]\n",
      "\n",
      "Class 52\tsauce:\n",
      "[[1743   65]\n",
      " [ 207  120]]\n",
      "\n",
      "Class 53\tcrab:\n",
      "[[2128    1]\n",
      " [   6    0]]\n",
      "\n",
      "Class 54\tfish:\n",
      "[[2027   13]\n",
      " [  74   21]]\n",
      "\n",
      "Class 55\tshellfish:\n",
      "[[2119    3]\n",
      " [   8    5]]\n",
      "\n",
      "Class 56\tshrimp:\n",
      "[[2082    8]\n",
      " [  31   14]]\n",
      "\n",
      "Class 57\tsoup:\n",
      "[[2108    5]\n",
      " [  14    8]]\n",
      "\n",
      "Class 58\tbread:\n",
      "[[1628   93]\n",
      " [ 204  210]]\n",
      "\n",
      "Class 59\tcorn:\n",
      "[[1980   10]\n",
      " [  31  114]]\n",
      "\n",
      "Class 60\thamburg:\n",
      "[[2134    0]\n",
      " [   1    0]]\n",
      "\n",
      "Class 61\tpizza:\n",
      "[[2116    6]\n",
      " [  10    3]]\n",
      "\n",
      "Class 62\t hanamaki baozi:\n",
      "[[2126    0]\n",
      " [   8    1]]\n",
      "\n",
      "Class 63\twonton dumplings:\n",
      "[[2125    0]\n",
      " [  10    0]]\n",
      "\n",
      "Class 64\tpasta:\n",
      "[[2082    5]\n",
      " [  38   10]]\n",
      "\n",
      "Class 65\tnoodles:\n",
      "[[2050   10]\n",
      " [  37   38]]\n",
      "\n",
      "Class 66\trice:\n",
      "[[1881   48]\n",
      " [  83  123]]\n",
      "\n",
      "Class 67\tpie:\n",
      "[[1917   57]\n",
      " [ 122   39]]\n",
      "\n",
      "Class 68\ttofu:\n",
      "[[2114    1]\n",
      " [  20    0]]\n",
      "\n",
      "Class 69\teggplant:\n",
      "[[2128    0]\n",
      " [   6    1]]\n",
      "\n",
      "Class 70\tpotato:\n",
      "[[1739   90]\n",
      " [ 148  158]]\n",
      "\n",
      "Class 71\tgarlic:\n",
      "[[2113    2]\n",
      " [  20    0]]\n",
      "\n",
      "Class 72\tcauliflower:\n",
      "[[2057    8]\n",
      " [  56   14]]\n",
      "\n",
      "Class 73\ttomato:\n",
      "[[1722   64]\n",
      " [ 108  241]]\n",
      "\n",
      "Class 74\tkelp:\n",
      "[[2133    0]\n",
      " [   2    0]]\n",
      "\n",
      "Class 75\tseaweed:\n",
      "[[2130    0]\n",
      " [   4    1]]\n",
      "\n",
      "Class 76\tspring onion:\n",
      "[[2074    4]\n",
      " [  56    1]]\n",
      "\n",
      "Class 77\trape:\n",
      "[[2114    0]\n",
      " [  20    1]]\n",
      "\n",
      "Class 78\tginger:\n",
      "[[2127    0]\n",
      " [   8    0]]\n",
      "\n",
      "Class 79\tokra:\n",
      "[[2132    1]\n",
      " [   2    0]]\n",
      "\n",
      "Class 80\tlettuce:\n",
      "[[1924   40]\n",
      " [  85   86]]\n",
      "\n",
      "Class 81\tpumpkin:\n",
      "[[2118    1]\n",
      " [  10    6]]\n",
      "\n",
      "Class 82\tcucumber:\n",
      "[[1952   19]\n",
      " [  86   78]]\n",
      "\n",
      "Class 83\twhite radish:\n",
      "[[2119    0]\n",
      " [  15    1]]\n",
      "\n",
      "Class 84\tcarrot:\n",
      "[[1715   22]\n",
      " [  84  314]]\n",
      "\n",
      "Class 85\tasparagus:\n",
      "[[2044   14]\n",
      " [  36   41]]\n",
      "\n",
      "Class 86\tbamboo shoots:\n",
      "[[2132    0]\n",
      " [   3    0]]\n",
      "\n",
      "Class 87\tbroccoli:\n",
      "[[1805   21]\n",
      " [  65  244]]\n",
      "\n",
      "Class 88\tcelery stick:\n",
      "[[2056   14]\n",
      " [  30   35]]\n",
      "\n",
      "Class 89\tcilantro mint:\n",
      "[[1810   61]\n",
      " [ 166   98]]\n",
      "\n",
      "Class 90\tsnow peas:\n",
      "[[2111    0]\n",
      " [  21    3]]\n",
      "\n",
      "Class 91\t cabbage:\n",
      "[[2099    3]\n",
      " [  31    2]]\n",
      "\n",
      "Class 92\tbean sprouts:\n",
      "[[2121    1]\n",
      " [  13    0]]\n",
      "\n",
      "Class 93\tonion:\n",
      "[[1945   32]\n",
      " [ 135   23]]\n",
      "\n",
      "Class 94\tpepper:\n",
      "[[1985   19]\n",
      " [  99   32]]\n",
      "\n",
      "Class 95\tgreen beans:\n",
      "[[2066    6]\n",
      " [  30   33]]\n",
      "\n",
      "Class 96\tFrench beans:\n",
      "[[1995   19]\n",
      " [  50   71]]\n",
      "\n",
      "Class 97\tking oyster mushroom:\n",
      "[[2132    0]\n",
      " [   3    0]]\n",
      "\n",
      "Class 98\tshiitake:\n",
      "[[2077    4]\n",
      " [  53    1]]\n",
      "\n",
      "Class 99\tenoki mushroom:\n",
      "[[2132    0]\n",
      " [   3    0]]\n",
      "\n",
      "Class 100\toyster mushroom:\n",
      "[[2133    0]\n",
      " [   2    0]]\n",
      "\n",
      "Class 101\twhite button mushroom:\n",
      "[[2091    7]\n",
      " [  27   10]]\n",
      "\n",
      "Class 102\tsalad:\n",
      "[[2125    0]\n",
      " [  10    0]]\n",
      "\n",
      "Class 103\tother ingredients:\n",
      "[[2059    4]\n",
      " [  71    1]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\kaush\\anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model\n",
    "evaluate_model(model, r\"C:\\Users\\kaush\\Documents\\ASE-ECE\\Sem 5\\AIML\\FoodSeg103 Stuff\\category_id.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
